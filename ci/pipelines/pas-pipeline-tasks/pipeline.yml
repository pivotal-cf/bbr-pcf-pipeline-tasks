---
#! to set pipeline run: fly set-pipeline -p "pas-pipeline-tasks" -c <(ytt -f "ci/pipelines/pas-pipeline-tasks/pipeline.yml" --data-values-file ./ci/pipelines/pas-pipeline-tasks/values.yml )
#@ load("@ytt:data", "data")

#! ************************************
#! Secrets we need to run this pipeline
#! ************************************

#! this needs to come first, else all other vars can't be resolved.
#! cerberus creds are required to access the teams vault instance managed by cerberus. The creds have been created manually via the vault-cli targetting the teams cerberus vault. Example steps to create an approle are here: https://developer.hashicorp.com/vault/docs/auth/approle the required value for policies is `restricted-admin` the auth method is mounted on the standard path.
cerberus: &cerberus
  role_id: ((cerberus-auth.role_id))
  secret_id: ((cerberus-auth.secret_id))

#! shepherd_account_key was needed on 2023-10-18 to claim shepherd environments. It was created using `shepherd create service-account` after logging in with WS1.
shepherd_sa_key: &shepherd_sa_key ((cerberus:shepherd.sa_key))

#! tanzunet_admin_token was needed on 2023-10-18 to get windows-TAS from tanzunet. Generated using tanzunet account in lastpass at Shared-Cryogenics/prod-essential/Tanzunet Non-Admin
pivnet_api_token: &pivnet_api_token ((cerberus:pivnet/mapbu-cryogenics-non-admin.legacy_api_token))

#! github_token was needed on 2023-10-18 to access PRs. Generated by using github account in lastpass at Shared-Cryogenics/infrastructure-root/github-ci-account
git_access_token: &git_access_token ((cerberus:github.access_token))

#! github_ssh_key was needed on 2023-10-18 to pull repos. Generated by using github account in lastpass at Shared-Cryogenics/infrastructure-root/github-ci-account
github_ssh_key: &github_ssh_key ((cerberus:github.ssh_key))

#! harbor_robot_{username,password} were needed on 2023-10-18 for accessing the cryogenics-essentials OCI image for running some of our tasks. The token can be generated by any team member who is logged in to https://harbor-repo.vmware.com/ using their own creds.
harbor_robot_username: &harbor_robot_username ((cerberus:harbor/robot-account.username))
harbor_robot_password: &harbor_robot_password ((cerberus:harbor/robot-account.password))

#! CloudGate credentials for the service user assuming a role in CF Diego Persistence CI
s3_credentials: &s3_credentials
  bucket: ((cerberus:om-backup-artifact.backup-bucket))
  region_name: ((cerberus:om-backup-artifact.region))
  access_key_id: ((cerberus:bbr/aws_s3_creds.access_key_id))
  secret_access_key: ((cerberus:bbr/aws_s3_creds.secret_access_key))
  aws_role_arn: ((cerberus:bbr/aws_s3_creds.assumed_role_arn))
  endpoint: ((cerberus:om-backup-artifact.endpoint))

#! **************
#! End of secrets
#! **************


#! **************
#! Params
#! **************
opsman_creds: &opsman_credentials
  OPSMAN_URL: ((.:pooled-env.ops_manager.url))
  OPSMAN_USERNAME: ((.:pooled-env.ops_manager.username))
  OPSMAN_PASSWORD: ((.:pooled-env.ops_manager.password))
  OPSMAN_PRIVATE_KEY: ((.:pooled-env.ops_manager_private_key))

number_of_apply_changes_retries: &number_of_apply_changes_retries 2
number_of_claim_env_retries: &number_of_claim_env_retries 5
number_of_download_retries: &number_of_download_retries 5
number_of_sats_retries: &number_of_sats_retries 10


#! **************
#! End of params
#! **************

var_sources:
- name: cerberus
  type: vault
  config:
    auth_backend: approle
    auth_params: *cerberus
    url: https://vault.console.cerberus.vmware.com/add164e1-f7fe-4e62-a548-a65690758636/
    path_prefix: secret

jobs:
- name: create-pr-once-a-week
  plan:
  - in_parallel:
    - get: once-a-week
      trigger: true
    - get: bbr-pipeline-tasks-repo-main
    - get: cryogenics-concourse-tasks
    - get: image-cryogenics-essentials
  - task: create-test-commit
    image: image-cryogenics-essentials
    config:
      platform: linux
      inputs:
      - name: bbr-pipeline-tasks-repo-main
      outputs:
      - name: branch_name
      - name: source-repo
      params:
        COMMIT_USERNAME: Cryogenics CI Bot
        COMMIT_USEREMAIL: mapbu-cryogenics@groups.vmware.com
      run:
        path: /bin/bash
        args:
        - -c
        - |
            #!/bin/bash
            pushd bbr-pipeline-tasks-repo-main
              git config user.name "${COMMIT_USERNAME}"
              git config user.email "${COMMIT_USEREMAIL}"

              DATE="$(date +%d-%m-%y)"
              BRANCH="trigger-tests-on-$DATE"
              git checkout -b $BRANCH
              echo "$DATE" > last_tested
              echo "$BRANCH" > ../branch_name/name

              git add last_tested
              git commit -m "update last_tested on $DATE"
            popd
            git clone bbr-pipeline-tasks-repo-main source-repo

  - load_var: pr_branch_name
    file: branch_name/name
  - put: bbr-pipeline-tasks-repo-main
    params:
      repository: source-repo
      branch: "((.:pr_branch_name))"
      force: true
  - task: create-pull-request
    file: cryogenics-concourse-tasks/github-automation/create-pr/task.yml
    image: image-cryogenics-essentials
    input_mapping:
      source-repo: bbr-pipeline-tasks-repo-main
    params:
      GH_TOKEN: *git_access_token
      BASE: main
      BRANCH: "((.:pr_branch_name))"
      LABELS: ci-trigger
      TITLE: ci-((.:pr_branch_name))
      MESSAGE: |
        This is an automatically generated Pull Request from the Cryogenics CI Bot.
        It is used to automatically create a PR against this repo to regularly trigger
        CI to test the tasks against new TAS Versions

- name: lint-pipeline
  plan:
    - in_parallel:
      - get: bbr-pipeline-tasks-repo
        trigger: true
      - get: cryogenics-concourse-tasks
      - get: image-bash
    - task: check-pipeline-for-stray-secrets
      image: image-bash
      file: cryogenics-concourse-tasks/pipeline-linting/check-pipeline-for-stray-secrets/task.yml
      input_mapping:
        pipeline-repo: bbr-pipeline-tasks-repo
      params:
        PIPELINE_TO_CHECK: ./pipeline-repo/ci/pipelines/pas-pipeline-tasks/pipeline.yml
#@ for v in data.values.tas_versions:
- name: #@ 'claim-env-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      passed:
      - lint-pipeline
      trigger: true
      version: every
    - put: #@ 'tas-' + v["version_slug"]
      attempts: *number_of_claim_env_retries
      timeout: 6h
      params:
        action: create
        duration: 24h
        resource: #@ 'tas-' + v["version_slug"]
        timeout: 6h

- name: #@ 'resize-director-and-control-vm-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      passed:
      - #@ 'claim-env-' + v["version_slug"]
      trigger: true
      version: every
    - get: #@ 'tas-' + v["version_slug"]
      passed:
      - #@ 'claim-env-' + v["version_slug"]
  - get: image-cryogenics-essentials
  - task: resize-vms-to-avoid-timeouts
    image: image-cryogenics-essentials
    config:
      platform: linux
      inputs:
      - name: bbr-pipeline-tasks-repo
      - name: #@ 'tas-' + v["version_slug"]
      run:
        path: /bin/bash
        args:
        - -c
        - |
          set -eu
          . <(smith -l tas-*/metadata om)
          CF_GUID="$(om curl -p /api/v0/staged/products | jq -r '.[] | select(.type == "cf").guid')"
          CONTROL_JOB_ID=$(om curl  -p /api/v0/staged/products/$CF_GUID/jobs | jq -r '.jobs[] | select(.name=="control").guid ')
          VM_TYPE="$(om curl -p /api/v0/vm_types | jq -r '[ .vm_types[] | select( .cpu >= 4 and .ephemeral_disk >= 50000 )][0].name')"
          UPDATE_CONFIG=$(om curl  -p /api/v0/staged/products/$CF_GUID/jobs/$CONTROL_JOB_ID/resource_config | jq ".instance_type.id = \"$VM_TYPE\"")
          om curl -x PUT -p /api/v0/staged/products/$CF_GUID/jobs/$CONTROL_JOB_ID/resource_config -d "$UPDATE_CONFIG"

          BOSH_GUID="$(om curl -p /api/v0/staged/products | jq -r '.[] | select(.type == "p-bosh").guid')"
          DIRECTOR_JOB_ID=$(om curl  -p /api/v0/staged/products/$BOSH_GUID/jobs | jq -r '.jobs[] | select(.name=="director").guid ')
          UPDATE_CONFIG=$(om curl  -p /api/v0/staged/products/$BOSH_GUID/jobs/$DIRECTOR_JOB_ID/resource_config | jq ".instance_type.id = \"$VM_TYPE\"")
          om curl -x PUT -p /api/v0/staged/products/$BOSH_GUID/jobs/$DIRECTOR_JOB_ID/resource_config -d "$UPDATE_CONFIG"

          om apply-changes

- name: #@ 'validate-sample-pipeline-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: validation-of-sample-pas-pipeline
      path: bbr-pipeline-tasks-repo
      status: pending
  - task: validate-pipeline
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/ci/tasks/validate-pipeline/task.yml
    input_mapping:
      pipeline: bbr-pipeline-tasks-repo
    params:
      PIPELINE_PATH: examples/pas-pipeline.yml
      SECRETS_PATH: examples/pas-secrets.yml
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: validation-of-sample-pas-pipeline
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: validation-of-sample-pas-pipeline
        path: bbr-pipeline-tasks-repo
        status: success

- name: #@ 'export-om-installation-' + v["version_slug"]
  serial: true
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: export-om-installation
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: export-om-installation
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/export-om-installation/task.yml
    params:
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: export-om-installation
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: export-om-installation
        path: bbr-pipeline-tasks-repo
        status: success
  - put: om-backup-artifact
    params:
      file: om-installation/installation_*.zip

- name: #@ 'bbr-backup-pas-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: bbr-release
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: bbr-backup-pas
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: extract-binary
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
  - task: bbr-backup-pas
    attempts: *number_of_apply_changes_retries
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/bbr-backup-pas/task.yml
    params:
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-pas
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-pas
        path: bbr-pipeline-tasks-repo
        status: success
  - in_parallel:
    - put: pas-backup-bucket
      params:
        file: pas-backup-artifact/pas-backup_*.tar
    - task: bbr-cleanup-pas
      image: image-cryogenics-essentials
      file: bbr-pipeline-tasks-repo/tasks/bbr-cleanup-pas/task.yml
      params:
        <<: *opsman_credentials

- name: #@ 'bbr-backup-director-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: bbr-release
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'resize-director-and-control-vm-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: bbr-backup-director
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: extract-binary
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
  - task: bbr-backup-director
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/bbr-backup-director/task.yml
    params:
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-director
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-director
        path: bbr-pipeline-tasks-repo
        status: success
  - in_parallel:
    - put: director-backup-bucket
      params:
        file: director-backup-artifact/director-backup_*.tar
    - task: bbr-cleanup-directors
      image: image-cryogenics-essentials
      file: bbr-pipeline-tasks-repo/tasks/bbr-cleanup-director/task.yml
      params:
        <<: *opsman_credentials

- name: #@ 'check-opsman-status-' + v["version_slug"]
  serial: true
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'validate-sample-pipeline-' + v["version_slug"]
      - #@ 'export-om-installation-' + v["version_slug"]
      - #@ 'bbr-backup-director-' + v["version_slug"]
      - #@ 'bbr-backup-pas-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'validate-sample-pipeline-' + v["version_slug"]
      - #@ 'export-om-installation-' + v["version_slug"]
      - #@ 'bbr-backup-director-' + v["version_slug"]
      - #@ 'bbr-backup-pas-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: check-opsman-status
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: check-opsman-status
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/check-opsman-status/task.yml
    attempts: *number_of_apply_changes_retries
    params: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: failure
  - task: check-opsman-status-during-apply-changes
    attempts: *number_of_apply_changes_retries
    image: image-cryogenics-essentials
    config:
      platform: linux

      inputs:
      - name: bbr-pipeline-tasks-repo
      - name: #@ 'tas-' + v["version_slug"]
      params: *opsman_credentials
      run:
        path: /bin/bash
        args:
        - -c
        - |
          set -eu

          source "bbr-pipeline-tasks-repo/scripts/om-cmd"
          om_cmd apply-changes &> /dev/null &

          sleep 60

          set +e
          output="$(./bbr-pipeline-tasks-repo/tasks/check-opsman-status/task.sh)"
          code=$?
          set -e

          test $code -ne 0
          echo "$output"
          grep "\"Apply Changes\" is in flight." <<< "$output"

          om_cmd apply-changes --reattach

    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: success

- name: #@ 'unclaim-env-' + v["version_slug"]
  plan:
  - get: bbr-pipeline-tasks-repo
    passed:
    - #@ 'check-opsman-status-' + v["version_slug"]
  - get: #@ 'tas-' + v["version_slug"]
    passed:
    - #@ 'check-opsman-status-' + v["version_slug"]
    trigger: true
  - put: #@ 'tas-' + v["version_slug"]
    params:
      action: release
      resource:  #@ 'tas-' + v["version_slug"]
#@ end

- name: merge-pr
  plan:
  - get: bbr-pipeline-tasks-repo
    trigger: true
    passed:
    #@ for v in data.values.tas_versions:
    - #@ 'unclaim-env-' + v["version_slug"]
    #@ end
  - put: bbr-pipeline-tasks-repo
    params:
      merge: true

resource_types:
- name: pivnet
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/pivotalcf/pivnet-resource
    tag: latest-final
- name: pull-request
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/cryogenics/pr-queue-resource
- name: shepherd
  source:
    repository: us-west2-docker.pkg.dev/shepherd-268822/shepherd2/concourse-resource
    tag: v1
  type: registry-image
resources:
- name: image-bash
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/library/bash
- name: cryogenics-concourse-tasks
  type: git
  icon: github
  source:
    uri: git@github.com:pivotal/cryogenics-concourse-tasks.git
    private_key: *github_ssh_key

- name: bbr-pipeline-tasks-repo-main
  type: git
  icon: github
  source:
    uri: git@github.com:pivotal-cf/bbr-pcf-pipeline-tasks
    private_key: *github_ssh_key

- name: image-cryogenics-essentials
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/cryogenics/essentials
    username: *harbor_robot_username
    password: *harbor_robot_password

- name: bbr-pipeline-tasks-repo
  type: pull-request
  icon: source-pull
  source:
    base_branch: main
    repository: pivotal-cf/bbr-pcf-pipeline-tasks
    disable_forks: true
    access_token: *git_access_token
    autosync_pr: true
    ignore_paths:
    - docker/*
    - README.md
    - tasks/bbr-backup-pks/*
    - tasks/bbr-backup-pks-clusters/*
    - tasks/bbr-cleanup-pks/*
    - tasks/bbr-cleanup-pks-clusters/*
    - tasks/lock-pks/*
    - tasks/unlock-pks/*

- name: om-backup-artifact
  type: s3
  source:
    <<: *s3_credentials
    regexp: installation_(.*).zip

- name: pas-backup-bucket
  type: s3
  source:
    <<: *s3_credentials
    regexp: pas-backup_(.*).tar

- name: director-backup-bucket
  type: s3
  source:
    <<: *s3_credentials
    regexp: director-backup_(.*).tar

- name: bbr-release
  type: pivnet
  source:
    api_token: *pivnet_api_token
    product_slug: p-bosh-backup-and-restore

- name: once-a-week
  type: time
  source:
    days: [Monday]

#@ for v in data.values.tas_versions:
- name: #@ 'tas-' + v["version_slug"]
  type: shepherd
  icon: pool
  source:
    url: https://v2.shepherd.run
    service-account-key: *shepherd_sa_key
    compatibility-mode: environments-app
    lease:
      namespace: cryogenics
      pool:
        namespace: official
        name: #@ v["pool_name"]
#@ end
