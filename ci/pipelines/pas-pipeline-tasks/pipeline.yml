---
#! to set pipeline run: fly set-pipeline -p "pas-pipeline-tasks" -c <(ytt -f "ci/pipelines/pas-pipeline-tasks/pipeline.yml" --data-values-file ./ci/pipelines/pas-pipeline-tasks/values.yml )
#@ load("@ytt:data", "data")

#! ************************************
#! Secrets we need to run this pipeline
#! ************************************

#! shepherd_account_key was needed on 2023-10-18 to claim shepherd environments. It was created using `shepherd create service-account` after logging in with WS1.
shepherd_sa_key: &shepherd_sa_key ((shepherd.sa_key))

#! tanzunet_admin_token was needed on 2023-10-18 to get windows-TAS from tanzunet. Generated using tanzunet account in lastpass at Shared-Cryogenics/prod-essential/Tanzunet Non-Admin 
pivnet_api_token: &pivnet_api_token ((pivnet/mapbu-cryogenics-non-admin.legacy_api_token))

#! github_token was needed on 2023-10-18 to access PRs. Generated by using github account in lastpass at Shared-Cryogenics/infrastructure-root/github-ci-account
git_access_token: &git_access_token ((github.access_token))

#! github_ssh_key was needed on 2023-10-18 to pull repos. Generated by using github account in lastpass at Shared-Cryogenics/infrastructure-root/github-ci-account
github_ssh_key: &github_ssh_key ((github.ssh_key))

#! harbor_robot_{username,password} were needed on 2023-10-18 for accessing the cryogenics-essentials OCI image for running some of our tasks. The token can be generated by any team member who is logged in to https://harbor-repo.vmware.com/ using their own creds.
harbor_robot_username: &harbor_robot_username ((harbor/robot-account.username))
harbor_robot_password: &harbor_robot_password ((harbor/robot-account.password))

#! CloudGate credentials for the service user assuming a role in CF Diego Persistence CI
s3_credentials: &s3_credentials
  bucket: ((om-backup-artifact.backup-bucket))
  region_name: ((om-backup-artifact.region))
  access_key_id: ((bbr/aws_s3_creds.access_key_id))
  secret_access_key: ((bbr/aws_s3_creds.secret_access_key))
  aws_role_arn: ((bbr/aws_s3_creds.assumed_role_arn))
  endpoint: ((om-backup-artifact.endpoint))

#! **************
#! End of secrets
#! **************


#! **************
#! Params
#! **************
opsman_creds: &opsman_credentials
  OPSMAN_URL: ((.:pooled-env.ops_manager.url))
  OPSMAN_USERNAME: ((.:pooled-env.ops_manager.username))
  OPSMAN_PASSWORD: ((.:pooled-env.ops_manager.password))
  OPSMAN_PRIVATE_KEY: ((.:pooled-env.ops_manager_private_key))

number_of_apply_changes_retries: &number_of_apply_changes_retries 2
number_of_claim_env_retries: &number_of_claim_env_retries 5
number_of_download_retries: &number_of_download_retries 5
number_of_sats_retries: &number_of_sats_retries 10
#! **************
#! End of params
#! **************

jobs:
- name: lint-pipeline
  plan:
    - in_parallel:
      - get: bbr-pipeline-tasks-repo
        trigger: true
      - get: cryogenics-concourse-tasks
      - get: image-bash
    - task: check-pipeline-for-stray-secrets
      image: image-bash
      file: cryogenics-concourse-tasks/pipeline-linting/check-pipeline-for-stray-secrets/task.yml
      input_mapping:
        pipeline-repo: bbr-pipeline-tasks-repo
      params:
        PIPELINE_TO_CHECK: ./pipeline-repo/ci/pipelines/pas-pipeline-tasks/pipeline.yml
#@ for v in data.values.tas_versions:
- name: #@ 'claim-env-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      passed: 
      - lint-pipeline
      trigger: true
      version: every
    - get: six-hours
      trigger: true
    - put: #@ 'tas-' + v["version_slug"]
      attempts: *number_of_claim_env_retries
      timeout: 6h
      params:
        action: create
        duration: 24h
        resource: #@ 'tas-' + v["version_slug"]
        timeout: 6h

- name: #@ 'validate-sample-pipeline-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: six-hours
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: validation-of-sample-pas-pipeline
      path: bbr-pipeline-tasks-repo
      status: pending
  - task: validate-pipeline
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/ci/tasks/validate-pipeline/task.yml
    input_mapping:
      pipeline: bbr-pipeline-tasks-repo
    params:
      PIPELINE_PATH: examples/pas-pipeline.yml
      SECRETS_PATH: examples/pas-secrets.yml
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: validation-of-sample-pas-pipeline
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: validation-of-sample-pas-pipeline
        path: bbr-pipeline-tasks-repo
        status: success

- name: #@ 'export-om-installation-' + v["version_slug"]
  serial: true
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: six-hours
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: export-om-installation
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: export-om-installation
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/export-om-installation/task.yml
    params: 
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: export-om-installation
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: export-om-installation
        path: bbr-pipeline-tasks-repo
        status: success
  - put: om-backup-artifact
    params:
      file: om-installation/installation_*.zip

- name: #@ 'bbr-backup-pas-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: bbr-release
    - get: six-hours
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: bbr-backup-pas
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: extract-binary
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
  - task: bbr-backup-pas
    attempts: *number_of_apply_changes_retries
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/bbr-backup-pas/task.yml
    params:
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-pas
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-pas
        path: bbr-pipeline-tasks-repo
        status: success
  - in_parallel:
    - put: pas-backup-bucket
      params:
        file: pas-backup-artifact/pas-backup_*.tar
    - task: bbr-cleanup-pas
      image: image-cryogenics-essentials
      file: bbr-pipeline-tasks-repo/tasks/bbr-cleanup-pas/task.yml
      params:
        <<: *opsman_credentials

- name: #@ 'bbr-backup-director-' + v["version_slug"]
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: bbr-release
    - get: six-hours
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'claim-env-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: bbr-backup-director
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: extract-binary
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/extract-bbr-binary/task.yml
  - task: bbr-backup-director
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/bbr-backup-director/task.yml
    params:
      <<: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-director
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: bbr-backup-director
        path: bbr-pipeline-tasks-repo
        status: success
  - in_parallel:
    - put: director-backup-bucket
      params:
        file: director-backup-artifact/director-backup_*.tar
    - task: bbr-cleanup-directors
      image: image-cryogenics-essentials
      file: bbr-pipeline-tasks-repo/tasks/bbr-cleanup-director/task.yml
      params:
        <<: *opsman_credentials

- name: #@ 'check-opsman-status-' + v["version_slug"]
  serial: true
  plan:
  - in_parallel:
    - get: bbr-pipeline-tasks-repo
      trigger: true
      version: every
      passed:
      - #@ 'validate-sample-pipeline-' + v["version_slug"]
      - #@ 'export-om-installation-' + v["version_slug"]
      - #@ 'bbr-backup-director-' + v["version_slug"]
      - #@ 'bbr-backup-pas-' + v["version_slug"]
    - get: six-hours
      trigger: true
      passed:
      - #@ 'validate-sample-pipeline-' + v["version_slug"]
      - #@ 'export-om-installation-' + v["version_slug"]
      - #@ 'bbr-backup-director-' + v["version_slug"]
      - #@ 'bbr-backup-pas-' + v["version_slug"]
    - get: #@ 'tas-' + v["version_slug"]
      trigger: true
      passed:
      - #@ 'validate-sample-pipeline-' + v["version_slug"]
      - #@ 'export-om-installation-' + v["version_slug"]
      - #@ 'bbr-backup-director-' + v["version_slug"]
      - #@ 'bbr-backup-pas-' + v["version_slug"]
    - get: image-cryogenics-essentials
  - put: bbr-pipeline-tasks-repo
    params:
      context: check-opsman-status
      path: bbr-pipeline-tasks-repo
      status: pending
  - file: #@ 'tas-' + v["version_slug"] + '/metadata'
    format: json
    load_var: pooled-env
  - task: check-opsman-status
    image: image-cryogenics-essentials
    file: bbr-pipeline-tasks-repo/tasks/check-opsman-status/task.yml
    attempts: *number_of_apply_changes_retries
    params: *opsman_credentials
    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: failure
  - task: check-opsman-status-during-apply-changes
    attempts: *number_of_apply_changes_retries
    image: image-cryogenics-essentials
    config:
      platform: linux

      inputs:
      - name: bbr-pipeline-tasks-repo
      - name: #@ 'tas-' + v["version_slug"]
      params: *opsman_credentials
      run:
        path: /bin/bash
        args:
        - -c
        - |
          set -eu

          source "bbr-pipeline-tasks-repo/scripts/om-cmd"
          om_cmd apply-changes &> /dev/null &
          
          sleep 60

          set +e
          output="$(./bbr-pipeline-tasks-repo/tasks/check-opsman-status/task.sh)"
          code=$?
          set -e

          test $code -ne 0
          echo "$output"
          grep "\"Apply Changes\" is in flight." <<< "$output"

          om_cmd apply-changes --reattach

    on_failure:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: failure
    on_success:
      put: bbr-pipeline-tasks-repo
      params:
        context: check-opsman-status
        path: bbr-pipeline-tasks-repo
        status: success

- name: #@ 'unclaim-env-' + v["version_slug"]
  plan:
  - get: bbr-pipeline-tasks-repo
    passed:
    - #@ 'check-opsman-status-' + v["version_slug"]
  - get: #@ 'tas-' + v["version_slug"]
    passed:
    - #@ 'check-opsman-status-' + v["version_slug"]
    trigger: true
  - put: #@ 'tas-' + v["version_slug"]
    params:
      action: release
      resource:  #@ 'tas-' + v["version_slug"]
#@ end

- name: merge-pr
  plan: 
  - get: bbr-pipeline-tasks-repo
    passed: 
    #@ for v in data.values.tas_versions:
    - #@ 'unclaim-env-' + v["version_slug"]
    #@ end
  - put: bbr-pipeline-tasks-repo
    params: 
      merge: true
    
resource_types:
- name: pivnet
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/pivotalcf/pivnet-resource
    tag: latest-final
- name: pull-request
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/cryogenics/pr-queue-resource
- name: shepherd
  source:
    repository: us-west2-docker.pkg.dev/shepherd-268822/shepherd2/concourse-resource
    tag: v1
  type: registry-image
resources:
- name: image-bash
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/dockerhub-proxy-cache/library/bash
- name: cryogenics-concourse-tasks
  type: git
  icon: github
  source:
    uri: git@github.com:pivotal/cryogenics-concourse-tasks.git
    private_key: *github_ssh_key
  
- name: image-cryogenics-essentials
  type: registry-image
  source:
    repository: harbor-repo.vmware.com/cryogenics/essentials
    username: *harbor_robot_username
    password: *harbor_robot_password

- name: bbr-pipeline-tasks-repo
  type: pull-request
  icon: source-pull
  source:
    base_branch: main
    repository: pivotal-cf/bbr-pcf-pipeline-tasks
    disable_forks: true
    access_token: *git_access_token 
    autosync_pr: true
    ignore_paths:
    - docker/*
    - README.md
    - tasks/bbr-backup-pks/*
    - tasks/bbr-backup-pks-clusters/*
    - tasks/bbr-cleanup-pks/*
    - tasks/bbr-cleanup-pks-clusters/*
    - tasks/lock-pks/*
    - tasks/unlock-pks/*

- name: om-backup-artifact
  type: s3
  source:
    <<: *s3_credentials
    regexp: installation_(.*).zip

- name: pas-backup-bucket
  type: s3
  source:
    <<: *s3_credentials
    regexp: pas-backup_(.*).tar

- name: director-backup-bucket
  type: s3
  source:
    <<: *s3_credentials
    regexp: director-backup_(.*).tar

- name: bbr-release
  type: pivnet
  source:
    api_token: *pivnet_api_token
    product_slug: p-bosh-backup-and-restore

- name: six-hours
  type: time
  source:
    interval: 6h
    start: 9:00 AM
    stop: 11:00 PM
    days: [Monday, Tuesday, Wednesday, Thursday, Friday]

#@ for v in data.values.tas_versions:
- name: #@ 'tas-' + v["version_slug"]
  type: shepherd
  icon: pool
  source:
    url: https://v2.shepherd.run
    service-account-key: *shepherd_sa_key
    compatibility-mode: environments-app
    lease:
      namespace: cryogenics
      pool:
        namespace: official
        name: #@ v["pool_name"]
#@ end
